# Example environment configuration for the document search stack.

# ============================================================================
# GEMINI API CONFIGURATION
# ============================================================================
# Google Gemini API key for embedding and summarization.
# Obtain from Google AI Studio: https://aistudio.google.com/app/apikey
# Used by both ingestion and search services.
GEMINI_API_KEY=your_gemini_api_key_here

# Embedding model and dimension
EMBED_MODEL=gemini-embedding-001
EMBED_DIM=3072

# Summary model (for document summarization)
SUMMARY_MODEL=gemini-2.5-flash

# ============================================================================
# SUMMARY PROVIDER CONFIGURATION
# ============================================================================
# Choose summary provider: GEMINI or OPENROUTER
SUMMARY_PROVIDER=GEMINI

# OpenRouter configuration (only needed if SUMMARY_PROVIDER=OPENROUTER)
OPENROUTER_API_KEY=
OPENROUTER_MODEL=openai/gpt-4o-mini

# ============================================================================
# MICROSOFT AZURE / ONEDRIVE CONFIGURATION
# ============================================================================
# Azure Active Directory credentials for Microsoft Graph API.
# The ingestion service uses these to access OneDrive files.
# App must have Files.Read.All permission.
MS_TENANT_ID=your_tenant_id
MS_CLIENT_ID=your_client_id
MS_CLIENT_SECRET=your_client_secret

# OneDrive configuration
# Drive ID: The unique identifier for your OneDrive or SharePoint drive
# Root Path: The folder path to sync (e.g., "AI/Document Filing")
ONEDRIVE_DRIVE_ID=your_drive_id
ONEDRIVE_ROOT_PATH=AI/Document Filing

# ============================================================================
# QDRANT CONFIGURATION
# ============================================================================
# Qdrant connection information.
# When using docker compose, use hostname 'qdrant' and port 6333.
# For local development outside Docker, use 'localhost'.
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_API_KEY=iniadalahapikeyqdrant

# Qdrant collection names
# These are the names of the vector collections in Qdrant
DOC_COLLECTION=documents
CHUNK_COLLECTION=chunks

# ============================================================================
# OCR SERVICE CONFIGURATION
# ============================================================================
# OCR service endpoint for PDF text extraction.
# Should point to a service that accepts PDF files and returns extracted text.
OCR_SERVICE_URL=https://your-ocr-service.com/ocr

# Maximum number of parallel OCR requests (pages processed simultaneously)
OCR_MAX_PARALLEL=5

# OCR cache directory (for local caching of OCR results)
# OCR_CACHE_DIR=/tmp/document_search_ocr_cache

# ============================================================================
# CHUNKING CONFIGURATION
# ============================================================================
# Text chunking parameters (in CHARACTERS, not tokens)
# CHUNK_SIZE: Size of each text chunk
# CHUNK_OVERLAP: Overlap between consecutive chunks
CHUNK_SIZE=2000
CHUNK_OVERLAP=200

# ============================================================================
# SCHEDULER CONFIGURATION
# ============================================================================
# Cron expression for automatic ingestion job (APScheduler format)
# Default: "0 0 * * *" (daily at midnight)
# Examples:
#   - Every hour: "0 * * * *"
#   - Every 6 hours: "0 */6 * * *"
#   - Daily at 2 AM: "0 2 * * *"
SCHEDULE_CRON=0 0 * * *

# ============================================================================
# OPERATIONAL FLAGS
# ============================================================================
# Dry run mode: Test without writing to Qdrant
DRY_RUN=false

# Skip summary generation (faster processing, but no summaries)
SKIP_SUMMARY=false

# Maximum documents to process (0 = unlimited, useful for testing)
MAX_DOCUMENTS=0

# Number of worker threads for parallel document processing
INGESTION_WORKERS=3

# Embedding batch size (number of texts to embed at once)
EMBED_BATCH_SIZE=16

# Maximum retry attempts for embeddings and summaries
EMBED_MAX_RETRIES=3
SUMMARY_MAX_RETRIES=3
